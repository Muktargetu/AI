{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMXfcyg3dOMj+PwOPfrkqW5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muktargetu/AI/blob/main/POS_tagging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRRksrza6eSv",
        "outputId": "262030cc-25d4-4706-cc58-8cc5c44e4471"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk.corpus\n",
        "nltk.download('treebank')\n",
        "nltk.download('brown')\n",
        "nltk.download('conll2000')\n",
        "nltk.download('universal_tagset')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "treebank_corpus = nltk.corpus.treebank.tagged_sents(tagset='universal')\n",
        "brown_corpus = nltk.corpus.brown.tagged_sents(tagset='universal')\n",
        "conll_corpus = nltk.corpus.conll2000.tagged_sents(tagset='universal')\n"
      ],
      "metadata": {
        "id": "bkAXUSNC6gZX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_sentences = treebank_corpus  + brown_corpus + conll_corpus"
      ],
      "metadata": {
        "id": "uerGvZ2Q6lRi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_sentences[8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8h3VSwNT6pbq",
        "outputId": "fa2f9a97-cf31-4e70-a6e4-8e0ff2bc0048"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('We', 'PRON'),\n",
              " (\"'re\", 'VERB'),\n",
              " ('talking', 'VERB'),\n",
              " ('about', 'ADP'),\n",
              " ('years', 'NOUN'),\n",
              " ('ago', 'ADP'),\n",
              " ('before', 'ADP'),\n",
              " ('anyone', 'NOUN'),\n",
              " ('heard', 'VERB'),\n",
              " ('of', 'ADP'),\n",
              " ('asbestos', 'NOUN'),\n",
              " ('having', 'VERB'),\n",
              " ('any', 'DET'),\n",
              " ('questionable', 'ADJ'),\n",
              " ('properties', 'NOUN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = [] # store input sequence\n",
        "Y = [] # store output sequence\n",
        "for sentence in tagged_sentences:\n",
        "  X_sentence = []\n",
        "  Y_sentence = []\n"
      ],
      "metadata": {
        "id": "do2woLe26som"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  for entity in sentence:\n",
        "    X_sentence.append(entity[0]) # entity[0] contains the word\n",
        "    Y_sentence.append(entity[1]) # entity[1] contains corresponding tag\n",
        "\n",
        "  X.append(X_sentence)\n",
        "  Y.append(Y_sentence)\n"
      ],
      "metadata": {
        "id": "XGxVlWUR6xuc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_words = len(set([word.lower() for sentence in X for word in sentence]))\n",
        "num_tags   = len(set([word.lower() for sentence in Y for word in sentence]))\n",
        "print(\"Total number of tagged sentences: {}\".format(len(X)))\n",
        "print(\"Vocabulary size: {}\".format(num_words))\n",
        "print(\"Total number of tags: {}\".format(num_tags))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onVL7yB361Vl",
        "outputId": "18b1cf23-372c-448a-9d06-3037838bf80e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of tagged sentences: 1\n",
            "Vocabulary size: 25\n",
            "Total number of tags: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('sample X: ', X[0], '\\n')\n",
        "print('sample Y: ', Y[0], '\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5H24FrZ7FgQ",
        "outputId": "5e6db254-08b8-4642-9d92-857accaf6992"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample X:  ['In', 'Los', 'Angeles', ',', 'for', 'example', ',', 'Central', 'has', 'had', 'a', 'strong', 'market', 'position', 'while', 'Unilab', \"'s\", 'presence', 'has', 'been', 'less', 'prominent', ',', 'according', 'to', 'Mr.', 'Harlow', '.'] \n",
            "\n",
            "sample Y:  ['ADP', 'NOUN', 'NOUN', '.', 'ADP', 'NOUN', '.', 'NOUN', 'VERB', 'VERB', 'DET', 'ADJ', 'NOUN', 'NOUN', 'ADP', 'NOUN', 'PRT', 'NOUN', 'VERB', 'VERB', 'ADV', 'ADJ', '.', 'VERB', 'PRT', 'NOUN', 'NOUN', '.'] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Length of first input sequence : {}\".format(len(X[0])))\n",
        "print(\"Length of first output sequence : {}\".format(len(Y[0])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAUKONpo7JOI",
        "outputId": "3a8a065f-c813-4b66-ee11-094dc7dd2171"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of first input sequence : 28\n",
            "Length of first output sequence : 28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# encode X\n",
        "word_tokenizer = Tokenizer()              # instantiate tokenizer\n",
        "word_tokenizer.fit_on_texts(X)            # fit tokenizer on data\n",
        "\n",
        "# use the tokenizer to encode input sequence\n",
        "X_encoded = word_tokenizer.texts_to_sequences(X)\n",
        "\n",
        "# encode Y\n",
        "tag_tokenizer = Tokenizer()\n",
        "tag_tokenizer.fit_on_texts(Y)\n",
        "Y_encoded = tag_tokenizer.texts_to_sequences(Y)\n"
      ],
      "metadata": {
        "id": "2fWX8qwH7MqV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"** Raw data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
        "print('X: ', X[0], '\\n')\n",
        "print('Y: ', Y[0], '\\n')\n",
        "print()\n",
        "print(\"** Encoded data point **\", \"\\n\", \"-\"*100, \"\\n\")\n",
        "print('X: ', X_encoded[0], '\\n')\n",
        "print('Y: ', Y_encoded[0], '\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8gLOhJ37UHh",
        "outputId": "c8f354e1-589e-464e-df7d-3121708319af"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "** Raw data point ** \n",
            " ---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "X:  ['In', 'Los', 'Angeles', ',', 'for', 'example', ',', 'Central', 'has', 'had', 'a', 'strong', 'market', 'position', 'while', 'Unilab', \"'s\", 'presence', 'has', 'been', 'less', 'prominent', ',', 'according', 'to', 'Mr.', 'Harlow', '.'] \n",
            "\n",
            "Y:  ['ADP', 'NOUN', 'NOUN', '.', 'ADP', 'NOUN', '.', 'NOUN', 'VERB', 'VERB', 'DET', 'ADJ', 'NOUN', 'NOUN', 'ADP', 'NOUN', 'PRT', 'NOUN', 'VERB', 'VERB', 'ADV', 'ADJ', '.', 'VERB', 'PRT', 'NOUN', 'NOUN', '.'] \n",
            "\n",
            "\n",
            "** Encoded data point ** \n",
            " ---------------------------------------------------------------------------------------------------- \n",
            "\n",
            "X:  [3, 4, 5, 1, 6, 7, 1, 8, 2, 9, 10, 11, 12, 13, 14, 15, 16, 17, 2, 18, 19, 20, 1, 21, 22, 23, 24, 25] \n",
            "\n",
            "Y:  [4, 1, 1, 3, 4, 1, 3, 1, 2, 2, 7, 5, 1, 1, 4, 1, 6, 1, 2, 2, 8, 5, 3, 2, 6, 1, 1, 3] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import pad_sequences\n",
        "\n",
        "# Pad each sequence to MAX_SEQ_LENGTH using KERAS’ pad_sequences() function.\n",
        "# Sentences longer than MAX_SEQ_LENGTH are truncated.\n",
        "# Sentences shorter than MAX_SEQ_LENGTH are padded with zeroes.\n",
        "# Truncation and padding can either be ‘pre’ or ‘post’.\n",
        "# For padding we are using ‘pre’ padding type, i.e. add zeroes on the left side.\n",
        "# For truncation, we are using ‘post’, i.e. truncate a sentence from right side.\n",
        "# sequences greater than 100 in length will be truncated\n",
        "\n",
        "MAX_SEQ_LENGTH = 100\n",
        "X_padded = pad_sequences(X_encoded, maxlen=MAX_SEQ_LENGTH,\n",
        "                                                  padding=\"pre\", truncating=\"post\")\n",
        "Y_padded = pad_sequences(Y_encoded, maxlen=MAX_SEQ_LENGTH,\n",
        "                                                   padding=\"pre\", truncating=\"post\")\n",
        "# print the first sequence\n",
        "print(X_padded[0], \"\\n\"*3)\n",
        "print(Y_padded[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7icZnTTj7YQx",
        "outputId": "f341fe2a-9f36-4d0c-bdef-68442f6e7a0c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  3  4  5  1  6  7  1  8  2  9 10 11 12 13 14 15 16 17  2 18 19 20  1 21\n",
            " 22 23 24 25] \n",
            "\n",
            "\n",
            "\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 1\n",
            " 1 3 4 1 3 1 2 2 7 5 1 1 4 1 6 1 2 2 8 5 3 2 6 1 1 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z1gtW-v-7oLj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}